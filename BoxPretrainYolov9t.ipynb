{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"âœ… CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"ğŸ§  Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BjeqTTBlhh9",
        "outputId": "58e31a7b-3131-4332-c028-39e229238c41"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CUDA Available: True\n",
            "ğŸ§  Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aK2bs0YAQgS",
        "outputId": "f187a134-1755-470e-9a81-3ec9f59d755a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.142-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.142-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.142 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Uw3IvPBLGy",
        "outputId": "9266cd01-3c2e-4580-8d85-9c3530798f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kzRWIy5vCCus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88bb2b1-c18a-4005-ddb3-27d7f150dbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9t.pt to 'yolov9t.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.74M/4.74M [00:00<00:00, 58.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = YOLO(\"yolov9t.pt\")  # Use yolov9.pt for a larger model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "%cd OIDv4_ToolKit\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQQb9AyGs58n",
        "outputId": "b3632b80-116e-44a1-af5a-82e23159419d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 422, done.\u001b[K\n",
            "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 422 (from 1)\u001b[K\n",
            "Receiving objects: 100% (422/422), 34.08 MiB | 28.89 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "/content/OIDv4_ToolKit\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Collecting awscli (from -r requirements.txt (line 3))\n",
            "  Downloading awscli-1.40.20-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Collecting botocore==1.38.21 (from awscli->-r requirements.txt (line 3))\n",
            "  Downloading botocore-1.38.21-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting docutils<=0.19,>=0.18.1 (from awscli->-r requirements.txt (line 3))\n",
            "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting s3transfer<0.13.0,>=0.12.0 (from awscli->-r requirements.txt (line 3))\n",
            "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.11/dist-packages (from awscli->-r requirements.txt (line 3)) (6.0.2)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli->-r requirements.txt (line 3))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli->-r requirements.txt (line 3))\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.38.21->awscli->-r requirements.txt (line 3))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.6.1)\n",
            "Downloading awscli-1.40.20-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.21-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.40.20 botocore-1.38.21 colorama-0.4.6 docutils-0.19 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py downloader --classes \"Box\" --type_csv train --limit 2000 --Dataset /content/OID\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5OSIXsItCkU",
        "outputId": "e073a2ab-a315-4071-8b42-39fafb29fde4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Box.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 42634 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 34601 KB/s, 33 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mBox\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 2212 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 2000 images.\u001b[0m\n",
            "    [INFO] | Download of 2000 images in train.\u001b[0m\n",
            "100% 2000/2000 [24:22<00:00,  1.37it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Box of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prepare YOLO directory structure\n",
        "!mkdir -p /content/openimages/images/train\n",
        "!mkdir -p /content/openimages/labels/train\n",
        "!cp /content/OID/train/Box/*.jpg /content/openimages/images/train/"
      ],
      "metadata": {
        "id": "nfCHUX22tSYC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Convert to YOLO format with class ID 80 (after COCO's 0â€“79)\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "oid_labels = \"/content/OID/train/Box/Label/\"\n",
        "oid_images = \"/content/OID/train/Box/\"\n",
        "yolo_labels = \"/content/openimages/labels/train/\"\n",
        "os.makedirs(yolo_labels, exist_ok=True)\n",
        "\n",
        "converted = 0\n",
        "for label_path in glob(os.path.join(oid_labels, \"*.txt\")):\n",
        "    base = os.path.basename(label_path).replace(\".txt\", \"\")\n",
        "    image_path = os.path.join(oid_images, base + \".jpg\")\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        w, h = img.size\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    yolo_lines = []\n",
        "    with open(label_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5 or parts[0] != \"Box\":\n",
        "                continue\n",
        "            xmin, ymin, xmax, ymax = map(float, parts[1:])\n",
        "            x_center = ((xmin + xmax) / 2) / w\n",
        "            y_center = ((ymin + ymax) / 2) / h\n",
        "            width = (xmax - xmin) / w\n",
        "            height = (ymax - ymin) / h\n",
        "            if width <= 0 or height <= 0:\n",
        "                continue\n",
        "            yolo_lines.append(f\"80 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "    if yolo_lines:\n",
        "        with open(os.path.join(yolo_labels, base + \".txt\"), \"w\") as out:\n",
        "            out.writelines(yolo_lines)\n",
        "        converted += 1\n",
        "\n",
        "print(f\"Converted {converted} box labels to YOLO format with class 80\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDn4moh7mVn3",
        "outputId": "b58c6e6b-8799-4a83-f9c0-dde209523779"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 2000 box labels to YOLO format with class 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Prepare new YAML with COCO + Box (class 80)\n",
        "coco_classes = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\",\n",
        "    \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
        "    \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
        "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "    \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\"\n",
        "]\n",
        "coco_classes.append(\"box\")  # add class 80\n",
        "\n",
        "yaml_path = \"/content/coco_plus_box.yaml\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(\"path: /content/openimages\\n\")\n",
        "    f.write(\"train: images/train\\n\")\n",
        "    f.write(\"val: images/train\\n\")\n",
        "    f.write(\"names:\\n\")\n",
        "    for i, name in enumerate(coco_classes):\n",
        "        f.write(f\"  {i}: {name}\\n\")\n",
        "\n",
        "print(\"coco_plus_box.yaml written with 81 classes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33LUoXmJna6c",
        "outputId": "e2cbfa24-545f-45ca-8895-24cd0f09f3ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco_plus_box.yaml written with 81 classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Fine-tune YOLOv9t while preserving COCO weights\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov9t.pt\")\n",
        "model.train(data=yaml_path, epochs=50, imgsz=640, batch=8, lr0=1e-5, freeze=15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14UmY8wLnvgo",
        "outputId": "463724c0-d9a4-4e61-b2d0-7eaed14d1050"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/coco_plus_box.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=15, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9t.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=81\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
            "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
            "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
            "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
            "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
            "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
            "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
            " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
            " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
            " 22        [15, 18, 21]  1    697741  ultralytics.nn.modules.head.Detect           [81, [64, 96, 128]]           \n",
            "YOLOv9t summary: 544 layers, 2,136,157 parameters, 2,136,141 gradients, 8.5 GFLOPs\n",
            "\n",
            "Transferred 1303/1339 items from pretrained weights\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.cv3.conv.weight'\n",
            "Freezing layer 'model.2.cv3.bn.weight'\n",
            "Freezing layer 'model.2.cv3.bn.bias'\n",
            "Freezing layer 'model.2.cv4.conv.weight'\n",
            "Freezing layer 'model.2.cv4.bn.weight'\n",
            "Freezing layer 'model.2.cv4.bn.bias'\n",
            "Freezing layer 'model.3.cv1.conv.weight'\n",
            "Freezing layer 'model.3.cv1.bn.weight'\n",
            "Freezing layer 'model.3.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.cv3.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv3.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.cv3.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv2.1.conv.weight'\n",
            "Freezing layer 'model.4.cv2.1.bn.weight'\n",
            "Freezing layer 'model.4.cv2.1.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.cv3.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv3.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.cv3.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv3.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.cv3.1.conv.weight'\n",
            "Freezing layer 'model.4.cv3.1.bn.weight'\n",
            "Freezing layer 'model.4.cv3.1.bn.bias'\n",
            "Freezing layer 'model.4.cv4.conv.weight'\n",
            "Freezing layer 'model.4.cv4.bn.weight'\n",
            "Freezing layer 'model.4.cv4.bn.bias'\n",
            "Freezing layer 'model.5.cv1.conv.weight'\n",
            "Freezing layer 'model.5.cv1.bn.weight'\n",
            "Freezing layer 'model.5.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.cv3.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv3.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.cv3.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv2.1.conv.weight'\n",
            "Freezing layer 'model.6.cv2.1.bn.weight'\n",
            "Freezing layer 'model.6.cv2.1.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.cv3.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv3.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.cv3.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv3.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.cv3.1.conv.weight'\n",
            "Freezing layer 'model.6.cv3.1.bn.weight'\n",
            "Freezing layer 'model.6.cv3.1.bn.bias'\n",
            "Freezing layer 'model.6.cv4.conv.weight'\n",
            "Freezing layer 'model.6.cv4.bn.weight'\n",
            "Freezing layer 'model.6.cv4.bn.bias'\n",
            "Freezing layer 'model.7.cv1.conv.weight'\n",
            "Freezing layer 'model.7.cv1.bn.weight'\n",
            "Freezing layer 'model.7.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.cv3.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv3.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.cv3.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv2.1.conv.weight'\n",
            "Freezing layer 'model.8.cv2.1.bn.weight'\n",
            "Freezing layer 'model.8.cv2.1.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.cv3.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv3.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.cv3.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv3.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.8.cv3.1.conv.weight'\n",
            "Freezing layer 'model.8.cv3.1.bn.weight'\n",
            "Freezing layer 'model.8.cv3.1.bn.bias'\n",
            "Freezing layer 'model.8.cv4.conv.weight'\n",
            "Freezing layer 'model.8.cv4.bn.weight'\n",
            "Freezing layer 'model.8.cv4.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv5.conv.weight'\n",
            "Freezing layer 'model.9.cv5.bn.weight'\n",
            "Freezing layer 'model.9.cv5.bn.bias'\n",
            "Freezing layer 'model.12.cv1.conv.weight'\n",
            "Freezing layer 'model.12.cv1.bn.weight'\n",
            "Freezing layer 'model.12.cv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.cv1.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv1.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.cv3.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv3.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.cv3.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv2.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv2.1.conv.weight'\n",
            "Freezing layer 'model.12.cv2.1.bn.weight'\n",
            "Freezing layer 'model.12.cv2.1.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.cv1.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv1.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv1.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.cv3.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv3.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.cv3.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv1.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv1.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv1.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv1.conv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.12.cv3.0.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.12.cv3.1.conv.weight'\n",
            "Freezing layer 'model.12.cv3.1.bn.weight'\n",
            "Freezing layer 'model.12.cv3.1.bn.bias'\n",
            "Freezing layer 'model.12.cv4.conv.weight'\n",
            "Freezing layer 'model.12.cv4.bn.weight'\n",
            "Freezing layer 'model.12.cv4.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1797.8Â±683.3 MB/s, size: 212.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/openimages/labels/train... 2000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<00:00, 2094.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/openimages/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 843.5Â±457.2 MB/s, size: 269.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/openimages/labels/train.cache... 2000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=1e-05' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000118, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      0.98G      1.114      4.313      1.441         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:12<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:30<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.414      0.386      0.347      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      1.38G      1.203      2.426      1.543         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839       0.55      0.511      0.507      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      1.39G      1.164      2.078      1.546         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.576      0.494      0.533      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      1.39G      1.125      1.901       1.53         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.609      0.521      0.566      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      1.39G       1.08       1.78      1.493         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.629       0.54      0.593      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      1.39G      1.092      1.727      1.492         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:05<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.624      0.545      0.589      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      1.39G      1.057      1.657      1.466         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.652      0.524      0.597      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      1.39G      1.055       1.64      1.464         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.631      0.547      0.597       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      1.39G      1.034      1.597      1.444         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.639      0.555      0.619      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      1.39G      1.037      1.564      1.442         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.651      0.558      0.621      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      1.39G      1.023      1.525      1.418         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.638      0.568      0.621      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      1.54G      1.019      1.522       1.42         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.654       0.58      0.637       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      1.54G      1.008      1.483      1.407         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.661      0.561       0.63      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      1.54G      1.005      1.482        1.4         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.653      0.576      0.638      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      1.54G      1.019      1.443      1.402         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.661      0.588      0.652      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      1.54G      1.004      1.436      1.399         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.682      0.569      0.647      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      1.54G     0.9891      1.411      1.387         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.675      0.579      0.649       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      1.54G     0.9864      1.376       1.37         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.688      0.581       0.66      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      1.54G     0.9912      1.369      1.386         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.676      0.591      0.659       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      1.54G     0.9837      1.359      1.379         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.688      0.579      0.659      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      1.54G     0.9931       1.37      1.396         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.683      0.585      0.663      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      1.54G     0.9793      1.353      1.378         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:07<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:31<00:00,  4.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.695      0.584      0.669      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      1.54G     0.9826      1.348      1.379         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839       0.68      0.582      0.661       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      1.54G     0.9761      1.312      1.376         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:32<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.704      0.586       0.67      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      1.54G     0.9773      1.319      1.373         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:05<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.705       0.59      0.674      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      1.54G     0.9531      1.299      1.358         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.702      0.589      0.672       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      1.54G     0.9599       1.28      1.362         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.692      0.602      0.672      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      1.54G     0.9624      1.305      1.357         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839       0.71      0.589      0.681        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      1.54G     0.9662      1.297      1.357         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.704      0.595      0.683      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      1.54G     0.9611      1.274      1.361         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:07<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.711      0.602      0.685      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      1.54G     0.9463      1.259      1.347         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.698      0.603      0.684      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      1.54G     0.9654      1.268      1.358         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.709      0.608      0.686      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      1.54G     0.9572      1.257      1.347         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.709        0.6      0.684      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      1.54G      0.965      1.268      1.352         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.722      0.596      0.687      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      1.54G      0.952       1.25      1.348         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.719      0.591      0.691       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      1.54G     0.9461       1.23      1.334         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:09<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.732      0.591      0.691      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      1.54G      0.941      1.234      1.328         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.732      0.592      0.693      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      1.54G     0.9245      1.203      1.331         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.722      0.604      0.696      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      1.54G     0.9457      1.218      1.339         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.728      0.605      0.698      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      1.54G     0.9452      1.217      1.335         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:03<00:00,  3.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.721      0.609      0.701      0.521\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      1.54G     0.8725      1.337      1.304         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:04<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839       0.71      0.604      0.689      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      1.54G     0.8829      1.262      1.318          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:00<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:31<00:00,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.735      0.595      0.697      0.519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      1.54G     0.8768      1.232      1.309         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:08<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.741      0.595      0.699       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      1.54G     0.8712      1.238      1.313         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:01<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.724      0.607      0.702      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      1.54G     0.8761      1.214      1.308         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:02<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.732      0.609      0.705      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      1.54G     0.8579      1.231      1.299         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:07<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:29<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.742      0.602      0.706      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      1.54G     0.8746      1.221       1.31         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:01<00:00,  4.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.741      0.602      0.707      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      1.54G     0.8664      1.207      1.299         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:01<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.748      0.602      0.707      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      1.54G     0.8623      1.215      1.304         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:01<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.745      0.603      0.707      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      1.54G     0.8649      1.209      1.303         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [01:01<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:28<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.749      0.602      0.708      0.531\n",
            "\n",
            "50 epochs completed in 1.303 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 4.9MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 4.9MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.142 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv9t summary (fused): 197 layers, 2,101,431 parameters, 0 gradients, 8.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:30<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       2000       4839      0.748      0.603      0.708      0.531\n",
            "                   box       2000       4839      0.748      0.603      0.708      0.531\n",
            "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([80])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7c5e1252d910>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,\n",
              "            0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99834,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99685,     0.99568,     0.99568,     0.99568,     0.99568,     0.99568,     0.99568,     0.99568,\n",
              "            0.99568,     0.99568,     0.99568,     0.99568,     0.99568,     0.99441,     0.99441,     0.99441,     0.99441,     0.99167,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,\n",
              "            0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.99143,     0.98916,     0.98916,     0.98815,     0.98815,     0.98815,     0.98721,     0.98721,     0.98721,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,\n",
              "            0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98646,     0.98557,     0.98557,     0.98474,     0.98474,     0.98288,     0.98288,     0.98282,     0.98282,     0.98282,     0.98282,     0.98282,\n",
              "            0.98282,     0.98282,     0.98282,     0.98282,     0.98282,     0.98282,     0.98194,     0.98108,      0.9807,      0.9807,      0.9807,      0.9807,      0.9807,      0.9807,     0.97922,     0.97922,     0.97922,      0.9777,      0.9777,      0.9777,     0.97638,     0.97638,     0.97638,\n",
              "            0.97638,     0.97563,     0.97425,     0.97425,     0.97425,     0.97382,     0.97382,     0.97382,     0.97382,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97328,     0.97184,     0.97113,      0.9708,      0.9708,\n",
              "             0.9708,     0.97015,     0.96948,     0.96887,     0.96887,     0.96882,     0.96882,     0.96882,     0.96882,     0.96882,     0.96882,      0.9676,      0.9676,     0.96716,     0.96716,     0.96684,     0.96684,     0.96684,     0.96642,     0.96642,     0.96642,     0.96624,     0.96624,\n",
              "            0.96624,     0.96624,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96607,     0.96587,     0.96587,     0.96587,     0.96587,     0.96587,     0.96538,     0.96483,     0.96483,     0.96483,     0.96483,     0.96483,\n",
              "            0.96483,     0.96483,     0.96443,     0.96443,     0.96408,     0.96408,     0.96352,     0.96241,     0.96201,     0.96201,     0.96171,     0.96171,     0.96171,     0.96003,     0.95899,     0.95841,     0.95799,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,\n",
              "            0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,      0.9574,      0.9574,     0.95726,     0.95726,     0.95726,     0.95571,     0.95526,     0.95489,     0.95481,     0.95481,     0.95481,     0.95481,\n",
              "            0.95382,     0.95265,     0.95265,     0.95265,     0.95214,     0.95182,     0.95036,     0.95006,     0.95006,     0.94928,     0.94928,     0.94849,     0.94849,     0.94809,     0.94668,     0.94481,      0.9437,      0.9437,      0.9437,     0.94296,     0.94296,     0.94268,     0.94174,\n",
              "            0.94142,     0.94105,     0.94041,     0.94041,     0.94041,     0.94041,     0.94041,     0.93853,     0.93676,     0.93463,     0.93401,     0.93401,     0.93357,     0.93337,     0.93263,     0.93223,      0.9315,     0.93121,     0.92992,     0.92974,     0.92949,     0.92949,     0.92924,\n",
              "             0.9285,     0.92819,     0.92718,     0.92718,     0.92643,     0.92571,     0.92456,     0.92315,     0.92315,     0.92224,     0.92224,     0.92151,     0.91992,     0.91932,     0.91854,     0.91659,     0.91597,     0.91505,     0.91505,     0.91398,     0.91338,     0.91308,     0.91245,\n",
              "            0.91107,     0.90913,     0.90774,     0.90587,     0.90542,     0.90542,     0.90542,     0.90514,     0.90508,     0.90508,     0.90407,     0.90407,     0.90407,     0.90318,     0.90269,     0.90256,     0.90256,     0.90117,     0.90094,     0.90094,     0.90064,     0.89953,     0.89953,\n",
              "            0.89873,     0.89725,     0.89642,     0.89542,     0.89441,     0.89441,     0.89356,     0.89332,      0.8928,     0.89228,     0.89099,     0.88903,     0.88848,     0.88744,     0.88682,     0.88489,     0.88366,     0.88292,      0.8828,     0.88259,     0.88076,      0.8803,     0.87905,\n",
              "            0.87745,     0.87745,      0.8771,     0.87534,      0.8751,     0.87364,     0.87321,     0.87278,     0.87259,     0.87203,     0.87176,     0.87176,     0.87115,     0.87115,     0.87012,     0.86863,      0.8679,     0.86684,     0.86584,     0.86394,     0.86345,     0.86264,     0.86213,\n",
              "            0.86213,     0.86213,     0.86164,     0.86138,     0.86126,     0.85964,     0.85833,     0.85766,     0.85725,     0.85725,     0.85505,     0.85317,     0.85227,     0.85218,     0.85179,      0.8512,     0.84972,     0.84923,       0.849,     0.84768,     0.84706,     0.84496,     0.84496,\n",
              "            0.84362,     0.84362,     0.84308,     0.84308,     0.84219,     0.84109,     0.83993,     0.83958,     0.83872,     0.83866,     0.83707,     0.83673,     0.83639,     0.83638,     0.83582,     0.83477,     0.83361,     0.83251,     0.83251,     0.83164,     0.83051,     0.82955,      0.8289,\n",
              "            0.82801,     0.82732,     0.82653,     0.82554,      0.8252,      0.8252,     0.82428,     0.82362,     0.82359,     0.82312,     0.82216,     0.82141,     0.82066,     0.82017,     0.81912,     0.81691,     0.81599,     0.81535,     0.81494,     0.81292,     0.81197,     0.81077,     0.81032,\n",
              "            0.80987,     0.80869,     0.80831,     0.80762,     0.80755,     0.80507,     0.80446,     0.80255,     0.80225,     0.80183,         0.8,     0.79936,     0.79726,     0.79686,     0.79547,     0.79347,     0.79155,     0.79116,     0.78841,     0.78714,     0.78549,     0.78462,     0.78372,\n",
              "             0.7828,     0.77989,     0.77899,     0.77738,     0.77627,     0.77539,     0.77335,     0.77281,     0.77177,     0.77133,     0.77053,     0.76929,     0.76871,     0.76792,     0.76644,     0.76622,     0.76427,     0.76303,     0.76146,     0.76063,     0.75888,     0.75794,     0.75667,\n",
              "            0.75469,     0.75318,     0.75136,     0.74923,     0.74808,     0.74725,     0.74434,      0.7441,     0.74123,     0.73975,     0.73897,     0.73824,     0.73728,     0.73486,     0.73228,     0.72991,     0.72935,      0.7289,     0.72692,     0.72285,     0.72064,      0.7197,     0.71712,\n",
              "            0.71439,     0.71202,     0.70995,     0.70763,     0.70533,     0.70355,     0.70129,     0.70028,     0.69694,     0.69443,      0.6928,     0.69213,     0.69108,     0.68857,     0.68806,     0.68732,     0.68729,     0.68613,     0.68412,     0.68289,     0.68137,     0.68127,     0.67968,\n",
              "             0.6787,     0.67582,      0.6737,     0.67354,     0.67216,     0.67093,     0.67029,     0.66921,     0.66617,     0.66443,     0.66415,     0.66256,     0.66139,     0.65901,       0.658,     0.65592,     0.65526,     0.65347,     0.65209,      0.6506,     0.64937,     0.64693,     0.64424,\n",
              "            0.64273,     0.64067,     0.63932,     0.63642,     0.63583,     0.63445,     0.63326,     0.63191,     0.63176,     0.62932,     0.62715,       0.625,     0.61893,     0.61695,     0.61594,     0.61299,     0.61052,     0.61043,     0.60947,     0.60905,     0.60785,       0.606,     0.60587,\n",
              "            0.60547,     0.60346,     0.60342,     0.59786,     0.59494,     0.59408,      0.5921,       0.591,     0.58937,     0.58775,     0.58463,      0.5821,     0.58137,     0.57837,     0.57677,      0.5754,     0.57277,     0.57007,     0.56826,     0.56578,     0.56403,     0.56192,     0.55945,\n",
              "            0.55751,     0.55745,     0.55309,      0.5516,      0.5507,     0.54945,     0.54695,     0.54339,     0.54214,     0.53915,     0.53752,     0.53558,     0.53277,     0.52951,     0.52685,     0.52446,     0.52404,     0.52237,     0.52173,     0.52132,     0.52037,     0.51844,     0.51639,\n",
              "            0.51324,     0.51161,      0.5102,     0.50838,     0.50636,     0.50287,     0.50118,     0.49868,     0.49758,     0.49499,     0.49157,     0.49091,     0.48999,     0.48941,     0.48661,     0.48442,     0.48373,     0.48133,     0.47565,     0.47402,     0.47154,     0.46666,     0.46481,\n",
              "            0.46193,     0.45803,     0.45733,      0.4532,     0.45272,     0.44975,     0.44818,     0.44598,     0.44307,     0.44266,     0.43854,     0.43468,     0.43277,     0.43197,     0.43048,     0.42945,     0.42719,     0.42566,      0.4243,     0.42088,     0.41864,     0.41752,      0.4163,\n",
              "            0.41544,      0.4135,      0.4122,     0.40892,     0.40152,     0.39827,     0.39542,     0.39228,     0.38983,     0.38888,     0.38543,     0.38328,     0.38203,     0.37963,     0.37741,     0.37412,     0.37295,     0.37143,      0.3676,      0.3659,     0.36387,     0.36264,     0.36061,\n",
              "            0.35944,     0.35865,     0.35643,     0.35456,     0.35367,     0.35209,     0.35005,     0.34925,     0.34738,     0.34685,     0.34111,     0.34086,     0.33763,     0.33536,      0.3328,     0.33128,     0.32993,     0.32917,     0.32707,     0.32487,     0.32002,     0.31833,     0.31693,\n",
              "             0.3156,     0.31103,     0.30803,     0.30477,     0.30154,      0.3004,     0.29984,      0.2974,     0.29653,     0.29478,     0.29052,     0.28955,     0.28953,     0.28454,     0.27986,     0.27679,     0.27576,      0.2711,     0.26976,     0.26775,     0.26484,     0.26268,     0.25883,\n",
              "            0.25762,      0.2564,     0.25439,     0.25334,     0.25091,     0.24748,     0.24484,     0.24193,     0.23908,     0.23718,      0.2353,     0.23195,     0.22903,     0.22666,     0.22347,     0.22162,     0.21837,     0.21501,     0.21363,     0.21007,      0.2091,     0.20689,     0.20524,\n",
              "            0.20152,     0.19974,      0.1985,     0.19638,     0.19274,     0.19086,     0.18877,     0.18669,     0.18516,     0.18299,     0.18077,     0.17983,     0.17776,     0.17472,     0.17267,     0.16786,     0.16541,     0.16344,     0.16202,     0.15931,     0.15763,      0.1555,     0.15448,\n",
              "            0.15199,     0.14996,     0.14773,     0.14628,     0.14435,      0.1413,     0.13923,     0.13811,     0.13432,     0.13295,     0.13192,     0.13046,     0.12887,     0.12748,     0.12592,     0.12368,     0.12272,     0.11995,     0.11728,     0.11655,     0.11553,     0.11391,     0.11204,\n",
              "            0.11092,     0.10972,     0.10692,     0.10457,     0.10312,     0.10285,     0.10124,    0.099749,     0.09723,     0.09305,    0.091474,    0.090363,    0.088824,    0.087276,    0.085395,    0.082384,    0.079012,    0.075476,    0.074318,    0.072922,    0.071709,    0.070095,    0.068898,\n",
              "           0.066964,    0.065745,     0.06428,     0.06093,    0.058613,    0.056733,    0.055056,    0.052985,    0.048805,     0.04677,    0.045226,    0.043409,    0.041639,    0.039705,    0.038155,    0.035802,     0.03305,    0.030492,      0.0286,    0.027401,     0.02666,     0.02592,    0.025179,\n",
              "           0.024438,    0.023698,    0.022957,    0.022217,    0.021476,    0.020736,    0.019995,    0.019255,    0.018514,    0.017773,    0.017033,    0.016292,    0.015552,    0.014811,    0.014071,     0.01333,    0.012589,    0.011849,    0.011108,    0.010368,   0.0096273,   0.0088867,   0.0081461,\n",
              "          0.0074056,    0.006665,   0.0059245,   0.0051839,   0.0044434,   0.0037028,   0.0029622,   0.0022217,   0.0014811,  0.00074056,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.054375,    0.054375,    0.077676,    0.098184,     0.11651,     0.13324,     0.14866,     0.16331,     0.17734,     0.19025,     0.20268,      0.2135,     0.22457,     0.23396,     0.24456,     0.25393,     0.26297,     0.27153,     0.28004,     0.28824,     0.29645,     0.30331,     0.31022,\n",
              "            0.31712,     0.32384,      0.3303,     0.33722,      0.3432,     0.34913,     0.35514,     0.36136,     0.36654,      0.3719,     0.37708,     0.38205,      0.3878,     0.39249,     0.39678,     0.40217,     0.40613,     0.41098,     0.41575,     0.41907,     0.42396,     0.42805,     0.43185,\n",
              "            0.43636,     0.43859,     0.44191,     0.44597,     0.44948,     0.45272,     0.45719,     0.46045,     0.46354,      0.4677,     0.47024,     0.47257,     0.47577,     0.47876,     0.48113,     0.48487,     0.48752,     0.48956,     0.49189,     0.49408,     0.49653,     0.49856,      0.5011,\n",
              "            0.50335,     0.50628,     0.50869,     0.51011,     0.51225,     0.51427,     0.51668,     0.51854,     0.52046,     0.52247,      0.5242,      0.5267,      0.5289,     0.53083,     0.53362,     0.53553,     0.53788,      0.5397,      0.5413,     0.54257,     0.54365,     0.54598,     0.54686,\n",
              "            0.54893,     0.54981,     0.55107,     0.55249,     0.55382,     0.55492,     0.55654,     0.55782,      0.5597,     0.56156,     0.56224,     0.56407,     0.56518,     0.56651,     0.56841,     0.56945,     0.57089,     0.57227,      0.5735,     0.57449,     0.57662,     0.57761,     0.57908,\n",
              "            0.58025,      0.5826,     0.58358,     0.58462,     0.58556,     0.58758,     0.58837,     0.58897,     0.59002,     0.59075,     0.59231,     0.59236,     0.59284,     0.59355,     0.59495,     0.59587,     0.59671,     0.59804,     0.59869,     0.59973,     0.60094,     0.60217,     0.60263,\n",
              "            0.60299,     0.60419,     0.60495,      0.6062,     0.60723,     0.60804,     0.60878,     0.60924,     0.61008,     0.61005,     0.61115,     0.61212,     0.61356,     0.61447,      0.6156,     0.61641,     0.61728,     0.61802,     0.61885,     0.61943,     0.61964,     0.62072,     0.62166,\n",
              "            0.62244,     0.62325,     0.62323,     0.62409,     0.62459,     0.62518,     0.62611,     0.62602,     0.62672,      0.6276,     0.62796,     0.62917,     0.62925,     0.62972,     0.63066,     0.63117,     0.63183,     0.63197,     0.63299,     0.63382,     0.63392,     0.63417,      0.6349,\n",
              "            0.63519,      0.6361,     0.63645,     0.63731,     0.63747,     0.63782,     0.63884,     0.63936,      0.6399,     0.64005,     0.64014,     0.64059,     0.64093,     0.64212,     0.64243,     0.64265,     0.64311,     0.64437,     0.64511,     0.64518,     0.64523,     0.64456,     0.64522,\n",
              "            0.64549,     0.64538,     0.64543,     0.64516,     0.64542,     0.64621,     0.64636,     0.64676,     0.64741,     0.64772,     0.64769,     0.64841,     0.64921,     0.64981,     0.65003,     0.65089,     0.65115,     0.65189,     0.65211,     0.65251,     0.65258,     0.65265,     0.65294,\n",
              "            0.65295,     0.65323,     0.65333,     0.65352,     0.65405,     0.65431,     0.65432,     0.65452,     0.65519,     0.65529,     0.65577,     0.65612,     0.65654,     0.65663,     0.65725,     0.65725,     0.65727,     0.65742,     0.65751,     0.65747,     0.65788,     0.65796,     0.65826,\n",
              "            0.65826,     0.65862,     0.65878,     0.65909,     0.65926,     0.65931,     0.65932,     0.65941,     0.65998,     0.66002,      0.6599,     0.65995,      0.6601,     0.65984,     0.65993,     0.66011,     0.66023,      0.6599,     0.66054,     0.66042,     0.66072,     0.66136,     0.66105,\n",
              "            0.66111,     0.66111,     0.66079,     0.66115,     0.66109,     0.66131,     0.66125,     0.66163,     0.66164,      0.6609,     0.66055,     0.66032,     0.66076,     0.66085,     0.66083,       0.661,     0.66104,     0.66105,     0.66069,     0.66085,     0.66107,     0.66117,     0.66131,\n",
              "            0.66169,     0.66192,     0.66222,     0.66212,     0.66253,     0.66247,     0.66284,     0.66278,     0.66294,     0.66327,      0.6634,     0.66337,     0.66371,      0.6641,      0.6641,     0.66449,     0.66442,     0.66515,     0.66519,      0.6652,     0.66561,     0.66553,     0.66573,\n",
              "            0.66565,     0.66608,     0.66623,     0.66627,     0.66668,     0.66673,     0.66729,     0.66734,     0.66731,     0.66694,     0.66685,     0.66692,     0.66696,     0.66715,     0.66719,     0.66741,     0.66755,     0.66746,     0.66789,     0.66794,     0.66765,     0.66726,     0.66719,\n",
              "            0.66713,     0.66717,     0.66722,     0.66726,     0.66738,     0.66758,      0.6675,     0.66743,     0.66748,      0.6674,     0.66731,     0.66792,     0.66784,     0.66746,     0.66751,     0.66771,     0.66729,     0.66733,     0.66791,     0.66796,     0.66746,      0.6675,     0.66739,\n",
              "            0.66744,     0.66702,     0.66696,     0.66688,     0.66699,     0.66704,       0.667,     0.66704,     0.66631,     0.66635,     0.66605,     0.66597,     0.66532,     0.66519,     0.66523,     0.66437,     0.66428,     0.66433,     0.66437,     0.66402,     0.66394,       0.664,     0.66367,\n",
              "            0.66359,     0.66311,     0.66303,     0.66333,     0.66324,     0.66331,     0.66323,     0.66351,     0.66355,     0.66321,     0.66311,     0.66264,     0.66268,     0.66224,     0.66228,     0.66208,     0.66226,     0.66218,     0.66211,     0.66216,      0.6624,     0.66232,     0.66147,\n",
              "            0.66151,      0.6618,     0.66172,     0.66195,     0.66199,     0.66146,      0.6615,     0.66105,     0.66109,     0.66077,     0.66058,      0.6605,     0.65921,     0.65925,     0.65912,     0.65916,     0.65862,     0.65866,     0.65893,     0.65898,     0.65814,     0.65804,      0.6572,\n",
              "            0.65725,     0.65703,     0.65708,     0.65628,     0.65619,     0.65553,     0.65557,     0.65511,     0.65515,     0.65509,     0.65514,     0.65433,     0.65437,     0.65378,     0.65384,     0.65388,     0.65324,     0.65314,      0.6524,     0.65244,     0.65183,     0.65175,     0.65146,\n",
              "             0.6515,     0.65054,     0.65045,     0.64959,      0.6495,     0.64906,     0.64898,     0.64778,     0.64769,     0.64716,     0.64707,     0.64647,     0.64651,     0.64603,     0.64607,     0.64531,     0.64522,     0.64455,     0.64459,     0.64406,     0.64404,     0.64408,     0.64307,\n",
              "            0.64298,     0.64216,     0.64207,     0.64135,     0.64126,     0.63926,      0.6393,     0.63884,     0.63875,     0.63729,     0.63733,     0.63687,     0.63678,     0.63622,     0.63613,     0.63573,     0.63577,     0.63548,     0.63539,     0.63501,     0.63492,     0.63332,     0.63323,\n",
              "            0.63265,      0.6327,     0.63176,     0.63167,     0.63162,     0.63167,     0.63078,     0.63082,     0.62985,     0.62976,     0.62886,      0.6289,     0.62869,      0.6286,     0.62741,     0.62639,     0.62629,     0.62589,     0.62593,     0.62553,     0.62544,      0.6248,     0.62471,\n",
              "            0.62404,     0.62395,     0.62294,     0.62298,     0.62241,     0.62232,     0.62178,     0.62182,      0.6209,      0.6208,     0.62041,     0.62031,     0.61912,     0.61903,     0.61808,     0.61812,     0.61767,     0.61758,     0.61728,     0.61719,     0.61657,     0.61647,     0.61581,\n",
              "            0.61585,     0.61521,     0.61526,     0.61464,     0.61468,     0.61395,     0.61227,     0.61231,     0.61125,     0.61115,     0.60992,     0.60982,     0.60893,     0.60883,     0.60806,      0.6081,     0.60688,     0.60692,     0.60614,     0.60618,     0.60496,       0.605,     0.60398,\n",
              "            0.60389,      0.6034,     0.60344,     0.60333,     0.60337,       0.602,     0.60177,     0.60183,     0.60082,     0.60072,     0.59937,     0.59927,     0.59891,     0.59895,     0.59831,     0.59821,     0.59751,     0.59741,     0.59687,     0.59677,     0.59609,     0.59614,     0.59618,\n",
              "            0.59572,     0.59562,     0.59438,     0.59428,     0.59268,     0.59258,     0.59156,     0.59146,     0.59061,     0.59045,     0.59035,     0.58983,     0.58973,     0.58893,     0.58898,     0.58804,     0.58794,     0.58709,     0.58695,     0.58619,     0.58609,     0.58548,       0.584,\n",
              "            0.58389,     0.58352,     0.58342,     0.58269,     0.58255,     0.58071,     0.58075,     0.57958,     0.57948,     0.57894,     0.57884,     0.57751,     0.57699,     0.57703,     0.57558,     0.57547,     0.57363,     0.57349,     0.57218,     0.57127,     0.57131,     0.57041,     0.57027,\n",
              "            0.57015,     0.57004,     0.56949,     0.56939,     0.56861,      0.5677,      0.5676,     0.56672,     0.56676,     0.56582,     0.56587,     0.56456,     0.56446,     0.56394,     0.56306,     0.56311,      0.5627,     0.56259,     0.56253,     0.56137,     0.56126,     0.56077,     0.56063,\n",
              "            0.56026,     0.56016,     0.55833,      0.5578,      0.5577,     0.55737,     0.55723,     0.55649,     0.55638,     0.55604,     0.55501,      0.5549,     0.55433,     0.55383,     0.55372,     0.55306,     0.55292,     0.55175,     0.55164,     0.55078,     0.54975,     0.54964,     0.54775,\n",
              "             0.5478,      0.5459,     0.54579,     0.54406,     0.54309,     0.54294,     0.54192,     0.54181,     0.53989,     0.53932,     0.53826,     0.53815,     0.53777,     0.53783,     0.53684,     0.53612,     0.53616,     0.53429,     0.53414,     0.53212,     0.53119,     0.53108,      0.5306,\n",
              "            0.53045,     0.52972,     0.52828,     0.52813,     0.52656,     0.52644,     0.52506,     0.52476,     0.52307,     0.52292,     0.52243,     0.52231,     0.52121,     0.52054,     0.52059,     0.51918,     0.51858,     0.51843,     0.51754,     0.51568,     0.51553,     0.51482,      0.5147,\n",
              "            0.51388,     0.51358,     0.51343,     0.51298,     0.51118,     0.50998,     0.50983,     0.50877,     0.50839,     0.50824,     0.50756,     0.50669,     0.50674,     0.50528,     0.50353,     0.50338,     0.50118,     0.49987,     0.49971,     0.49948,      0.4978,     0.49764,     0.49587,\n",
              "            0.49418,     0.49386,      0.4937,     0.49123,     0.48921,     0.48735,     0.48719,      0.4854,     0.48337,     0.48321,     0.48281,     0.48124,     0.48108,     0.47935,     0.47846,     0.47714,     0.47698,     0.47547,     0.47443,     0.47427,     0.47355,     0.47306,     0.47243,\n",
              "            0.47164,     0.47169,     0.47035,     0.46736,     0.46534,     0.46518,     0.46422,     0.46306,     0.46145,     0.46128,     0.45918,     0.45828,     0.45648,     0.45631,     0.45485,     0.45395,     0.45252,     0.45133,     0.45074,     0.45007,      0.4499,     0.44828,     0.44759,\n",
              "            0.44617,     0.44378,     0.44361,     0.44214,     0.44021,     0.43802,     0.43654,     0.43637,     0.43563,     0.43344,     0.43205,      0.4311,     0.42811,     0.42793,     0.42572,     0.42324,     0.42307,     0.42132,     0.42003,     0.41682,     0.41541,     0.41412,      0.4122,\n",
              "            0.41202,     0.41101,     0.40945,      0.4071,     0.40507,     0.40351,     0.40226,     0.39963,     0.39785,     0.39594,     0.39598,     0.39446,     0.39021,     0.38781,     0.38593,     0.38325,     0.38203,     0.38096,     0.38077,     0.37999,     0.37809,      0.3768,     0.37571,\n",
              "             0.3742,     0.37338,     0.37207,     0.37098,     0.37042,      0.3696,     0.36778,     0.36505,     0.36269,     0.35893,     0.35823,     0.35684,     0.35544,     0.35432,     0.35208,     0.35102,     0.34945,     0.34762,     0.34648,     0.34507,      0.3428,     0.34016,     0.33981,\n",
              "            0.33896,     0.33696,      0.3325,     0.33126,     0.33054,     0.32966,     0.32741,     0.32658,     0.32442,     0.32239,     0.31933,     0.31811,     0.31713,     0.31537,      0.3114,     0.30985,     0.30859,     0.30519,     0.30395,     0.30033,     0.29794,     0.29573,      0.2935,\n",
              "            0.28891,     0.28755,     0.28642,     0.28292,     0.28002,     0.27785,     0.27326,     0.27075,     0.26676,     0.26515,     0.26442,     0.26076,     0.25685,     0.25596,     0.25342,     0.25237,      0.2486,     0.24601,     0.24221,     0.24042,     0.23931,     0.23512,     0.23204,\n",
              "            0.22867,     0.22378,     0.22155,     0.22085,     0.21821,      0.2159,     0.21259,     0.20993,     0.20703,      0.2068,     0.20423,      0.1992,     0.19617,     0.19346,     0.18939,     0.18632,     0.18085,     0.17877,     0.17567,     0.17048,       0.167,     0.16106,     0.15824,\n",
              "            0.15507,     0.15223,     0.14939,     0.14405,     0.14296,     0.13758,     0.13434,     0.12927,     0.12563,     0.12125,     0.11684,     0.11462,     0.11019,     0.10499,       0.102,     0.10012,    0.093738,    0.088827,    0.082751,    0.080099,    0.078527,    0.075069,    0.071599,\n",
              "           0.068886,    0.064233,    0.061112,     0.05837,    0.053666,    0.050117,     0.04695,    0.041794,    0.038203,    0.034598,    0.032581,    0.029142,    0.027334,    0.025704,    0.020839,    0.018793,    0.017555,     0.01656,    0.013853,    0.012201,    0.010546,   0.0095841,   0.0076378,\n",
              "           0.006386,   0.0047214,   0.0038777,   0.0029612,   0.0013631,  0.00099836,  0.00066112,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.027978,    0.027978,    0.040482,    0.051762,    0.062073,    0.071694,     0.08074,    0.089495,    0.098034,     0.10605,      0.1139,     0.12085,     0.12808,     0.13432,     0.14143,     0.14782,     0.15406,     0.16011,     0.16614,       0.172,     0.17798,     0.18307,     0.18825,\n",
              "            0.19347,     0.19859,     0.20363,     0.20902,     0.21378,     0.21853,     0.22338,     0.22844,     0.23273,     0.23719,     0.24155,     0.24581,     0.25068,     0.25482,      0.2587,     0.26344,     0.26702,     0.27143,     0.27569,     0.27881,     0.28331,      0.2871,     0.29083,\n",
              "            0.29501,     0.29734,     0.30067,     0.30463,     0.30808,     0.31128,     0.31568,     0.31916,     0.32226,     0.32649,      0.3292,     0.33183,     0.33527,     0.33854,      0.3412,     0.34509,       0.348,     0.35054,     0.35317,     0.35583,     0.35858,      0.3612,      0.3643,\n",
              "            0.36694,     0.37028,     0.37323,     0.37503,     0.37753,     0.37992,     0.38289,     0.38524,      0.3876,     0.39019,     0.39238,     0.39534,     0.39798,     0.40044,     0.40379,     0.40603,     0.40891,     0.41106,     0.41338,     0.41515,     0.41689,     0.42006,     0.42146,\n",
              "            0.42412,     0.42548,     0.42736,     0.42927,     0.43145,     0.43324,     0.43562,     0.43732,     0.43976,     0.44227,     0.44359,     0.44623,     0.44804,     0.45008,     0.45277,     0.45439,     0.45636,     0.45866,     0.46024,      0.4619,     0.46505,     0.46665,      0.4688,\n",
              "             0.4705,     0.47409,     0.47547,     0.47709,     0.47843,     0.48147,     0.48288,     0.48428,      0.4858,     0.48705,     0.48961,     0.49021,     0.49149,     0.49265,     0.49475,      0.4964,     0.49784,     0.50036,     0.50163,     0.50348,     0.50548,     0.50751,     0.50837,\n",
              "            0.50936,     0.51157,     0.51306,     0.51516,     0.51706,     0.51875,     0.52046,     0.52238,     0.52395,     0.52497,     0.52671,     0.52847,     0.53107,     0.53288,     0.53503,     0.53671,     0.53817,     0.53984,     0.54135,     0.54294,     0.54338,     0.54528,     0.54721,\n",
              "             0.5489,      0.5504,     0.55109,     0.55281,      0.5541,     0.55528,     0.55699,     0.55785,     0.55923,       0.561,     0.56213,     0.56443,     0.56469,     0.56597,      0.5679,     0.56951,     0.57087,     0.57149,     0.57331,     0.57535,     0.57551,     0.57634,     0.57787,\n",
              "            0.57901,     0.58095,     0.58238,      0.5841,     0.58437,     0.58569,     0.58773,     0.58932,      0.5906,     0.59166,     0.59197,     0.59304,     0.59484,     0.59719,     0.59834,     0.59873,     0.59983,     0.60234,     0.60454,     0.60533,     0.60542,     0.60616,     0.60779,\n",
              "            0.60902,     0.61021,     0.61029,      0.6108,     0.61177,     0.61351,      0.6138,     0.61502,      0.6167,     0.61829,     0.61841,     0.62006,     0.62169,     0.62314,     0.62356,     0.62549,     0.62703,     0.62876,     0.62928,     0.63081,     0.63203,     0.63342,     0.63397,\n",
              "            0.63473,     0.63581,       0.636,     0.63749,      0.6392,     0.64034,     0.64063,     0.64185,     0.64373,      0.6439,     0.64541,     0.64643,     0.64847,     0.64865,     0.65026,     0.65185,      0.6521,     0.65319,     0.65397,      0.6541,     0.65552,      0.6567,     0.65729,\n",
              "            0.65915,     0.66029,     0.66062,     0.66234,     0.66391,     0.66401,      0.6651,     0.66634,     0.66794,     0.66802,     0.66897,     0.66919,      0.6706,     0.67116,     0.67136,     0.67244,     0.67352,     0.67343,     0.67553,     0.67596,     0.67657,      0.6786,     0.68006,\n",
              "            0.68038,     0.68131,      0.6813,     0.68255,     0.68354,     0.68408,     0.68514,     0.68643,     0.68669,      0.6872,     0.68823,     0.68817,     0.68978,     0.69005,      0.6909,     0.69185,     0.69196,     0.69259,     0.69317,     0.69352,     0.69476,     0.69497,     0.69604,\n",
              "            0.69739,     0.69816,     0.69933,     0.69932,     0.70106,     0.70229,     0.70331,     0.70411,     0.70457,     0.70643,     0.70719,     0.70753,     0.70897,     0.71093,      0.7112,     0.71289,     0.71302,     0.71523,     0.71533,     0.71698,     0.71828,     0.71824,     0.71972,\n",
              "            0.71968,     0.72226,     0.72389,     0.72399,     0.72526,     0.72536,     0.72757,     0.72767,     0.72846,     0.72938,     0.72934,     0.73073,     0.73084,     0.73218,     0.73227,     0.73386,     0.73526,     0.73523,     0.73726,     0.73737,     0.73742,     0.73877,     0.73873,\n",
              "            0.74087,     0.74098,     0.74233,     0.74244,     0.74398,     0.74573,     0.74569,     0.74789,       0.748,     0.74915,     0.74911,     0.75114,     0.75111,     0.75215,     0.75227,     0.75441,     0.75532,     0.75542,     0.75724,     0.75736,     0.75875,     0.75885,     0.75991,\n",
              "            0.76003,     0.76165,      0.7629,     0.76287,     0.76466,     0.76478,     0.76608,     0.76618,     0.76703,     0.76715,     0.76862,     0.76859,     0.76993,     0.77115,     0.77125,     0.77151,     0.77148,     0.77244,     0.77256,     0.77427,     0.77424,     0.77499,     0.77615,\n",
              "            0.77612,     0.77722,     0.77719,     0.77898,     0.77895,     0.77972,     0.77969,     0.78172,     0.78183,     0.78288,     0.78285,     0.78427,     0.78438,     0.78624,     0.78635,     0.78736,      0.7883,     0.78827,     0.78983,     0.78995,     0.79149,     0.79146,     0.79197,\n",
              "            0.79211,     0.79305,     0.79302,     0.79458,      0.7947,     0.79602,     0.79613,      0.7981,     0.79822,     0.79997,     0.80177,     0.80174,     0.80233,     0.80245,     0.80377,     0.80389,     0.80529,     0.80541,     0.80711,     0.80723,     0.80829,     0.80826,      0.8089,\n",
              "            0.80903,     0.80971,     0.80984,     0.81024,     0.81021,     0.81182,     0.81195,     0.81278,     0.81291,     0.81411,     0.81424,     0.81542,     0.81554,     0.81669,     0.81853,     0.81866,     0.81945,     0.81942,     0.82105,     0.82118,     0.82174,     0.82171,     0.82237,\n",
              "             0.8225,      0.8234,     0.82337,     0.82426,     0.82423,     0.82503,       0.825,     0.82532,     0.82529,      0.8263,     0.82628,     0.82737,     0.82751,     0.82843,     0.82857,     0.82882,      0.8288,     0.82966,      0.8298,     0.83037,     0.83159,     0.83173,     0.83251,\n",
              "            0.83248,     0.83471,     0.83468,     0.83571,     0.83568,     0.83659,     0.83674,     0.83848,     0.83845,     0.83906,      0.8392,     0.83992,     0.83989,     0.84102,     0.84099,     0.84197,     0.84212,     0.84236,     0.84233,     0.84301,     0.84298,     0.84328,     0.84325,\n",
              "            0.84476,     0.84491,     0.84467,     0.84464,     0.84688,     0.84703,     0.84853,     0.84868,     0.84896,     0.84893,     0.84989,     0.85004,     0.85137,     0.85134,      0.8521,     0.85292,     0.85289,     0.85475,     0.85491,     0.85719,     0.85716,     0.85698,     0.85696,\n",
              "            0.85791,     0.85789,     0.85937,     0.85953,     0.86005,     0.86002,     0.86139,     0.86155,     0.86137,     0.86135,     0.86212,     0.86209,     0.86176,     0.86174,     0.86215,     0.86231,     0.86343,     0.86341,     0.86392,      0.8639,     0.86583,      0.8658,     0.86664,\n",
              "            0.86681,     0.86771,     0.86787,     0.86817,     0.86834,        0.87,     0.87117,     0.87134,     0.87145,     0.87142,     0.87172,      0.8717,     0.87272,     0.87269,     0.87323,      0.8734,      0.8742,     0.87437,     0.87625,     0.87643,     0.87725,     0.87743,     0.87719,\n",
              "            0.87717,     0.87817,     0.87835,     0.88012,      0.8803,     0.88095,     0.88189,     0.88213,     0.88265,     0.88262,     0.88262,      0.8826,      0.8843,     0.88449,     0.88675,     0.88673,     0.88724,     0.88722,     0.88846,     0.88844,     0.88952,     0.88974,     0.88993,\n",
              "             0.8913,     0.89128,     0.89274,     0.89272,     0.89341,     0.89339,     0.89422,     0.89419,     0.89507,     0.89575,     0.89573,     0.89633,     0.89631,     0.89726,     0.89746,     0.89846,     0.89844,     0.89935,     0.89932,     0.90062,      0.9006,     0.90084,     0.90052,\n",
              "            0.90049,      0.9019,     0.90188,     0.90247,     0.90244,     0.90292,     0.90312,     0.90331,     0.90329,     0.90393,     0.90391,     0.90363,     0.90435,     0.90455,     0.90513,     0.90511,     0.90511,     0.90508,      0.9048,     0.90656,     0.90677,     0.90913,      0.9091,\n",
              "            0.91106,     0.91104,     0.91172,      0.9117,     0.91235,     0.91338,     0.91336,     0.91324,     0.91346,     0.91472,     0.91501,      0.9148,     0.91478,     0.91591,     0.91584,     0.91605,     0.91732,      0.9173,     0.91827,     0.91957,     0.91955,     0.92071,     0.92069,\n",
              "            0.92146,     0.92144,      0.9226,     0.92315,     0.92313,     0.92307,     0.92304,     0.92291,     0.92289,     0.92438,     0.92567,     0.92565,     0.92613,     0.92677,     0.92675,     0.92708,     0.92705,     0.92685,     0.92684,     0.92845,     0.92917,     0.92915,     0.92935,\n",
              "            0.92967,     0.92987,     0.92985,     0.93138,     0.93259,     0.93256,     0.93332,      0.9333,     0.93392,     0.93383,     0.93459,     0.93458,     0.93547,      0.9358,     0.93671,     0.93948,     0.93973,     0.94013,     0.94011,      0.9403,     0.94065,     0.94063,     0.94105,\n",
              "            0.94102,     0.94141,     0.94267,     0.94265,     0.94292,      0.9429,      0.9432,     0.94366,     0.94343,     0.94341,     0.94384,     0.94382,     0.94539,     0.94665,       0.947,     0.94845,     0.94838,     0.94836,     0.94927,     0.94955,     0.94953,     0.94996,     0.94995,\n",
              "            0.94984,     0.95033,     0.95031,      0.9513,     0.95213,     0.95251,      0.9525,     0.95237,     0.95232,     0.95231,     0.95329,     0.95433,      0.9547,     0.95464,     0.95444,     0.95442,     0.95501,     0.95565,     0.95564,     0.95671,     0.95708,     0.95706,     0.95686,\n",
              "            0.95724,     0.95776,     0.95775,     0.95748,     0.95725,     0.95705,     0.95703,     0.95683,      0.9566,     0.95658,     0.95654,     0.95636,     0.95634,     0.95672,     0.95662,     0.95706,     0.95704,     0.95746,     0.95793,     0.95792,     0.95784,     0.95897,      0.9589,\n",
              "            0.95944,     0.95986,      0.9617,       0.962,     0.96241,     0.96239,     0.96274,     0.96404,     0.96388,     0.96387,     0.96429,      0.9642,     0.96466,     0.96464,      0.9645,     0.96441,     0.96427,     0.96416,     0.96475,     0.96533,     0.96531,     0.96581,     0.96574,\n",
              "            0.96561,     0.96604,     0.96602,     0.96588,      0.9657,     0.96549,     0.96534,     0.96532,     0.96525,     0.96504,     0.96558,     0.96618,     0.96589,     0.96587,     0.96635,     0.96681,      0.9668,     0.96663,      0.9665,     0.96691,     0.96749,     0.96737,     0.96865,\n",
              "            0.96863,     0.96854,     0.96839,     0.96817,     0.96914,     0.97009,     0.97074,     0.97051,     0.97112,     0.97196,      0.9725,     0.97317,     0.97282,     0.97261,     0.97245,     0.97222,     0.97375,     0.97366,     0.97364,     0.97358,     0.97342,     0.97414,     0.97405,\n",
              "            0.97561,     0.97555,      0.9763,     0.97621,     0.97617,     0.97611,     0.97765,      0.9775,     0.97909,     0.98063,     0.98058,     0.98049,      0.9804,     0.98033,     0.98018,     0.98103,      0.9828,     0.98269,     0.98262,     0.98254,      0.9824,     0.98224,     0.98222,\n",
              "            0.98216,     0.98204,     0.98416,     0.98467,     0.98463,     0.98458,     0.98548,     0.98646,     0.98635,     0.98625,     0.98609,     0.98603,     0.98598,     0.98589,     0.98568,      0.9856,     0.98553,     0.98534,     0.98638,     0.98619,     0.98706,      0.9871,     0.98797,\n",
              "            0.98912,     0.98907,     0.99143,     0.99131,     0.99121,     0.99113,     0.99095,     0.99086,      0.9907,     0.99064,     0.99061,     0.99046,     0.99063,     0.99239,     0.99434,     0.99431,     0.99565,      0.9956,     0.99552,     0.99549,     0.99546,     0.99537,      0.9953,\n",
              "            0.99681,     0.99673,     0.99834,     0.99834,     0.99832,      0.9983,     0.99827,     0.99824,     0.99821,     0.99821,     0.99819,     0.99814,      0.9981,     0.99807,     0.99803,     0.99799,     0.99793,      0.9979,     0.99786,     0.99779,     0.99774,     0.99765,      0.9976,\n",
              "            0.99755,      0.9975,     0.99745,     0.99735,     0.99732,     0.99721,     0.99714,     0.99702,     0.99693,     0.99681,     0.99668,     0.99661,     0.99647,     0.99628,     0.99617,     0.99609,     0.99582,     0.99557,     0.99524,     0.99507,     0.99497,     0.99473,     0.99447,\n",
              "            0.99424,     0.99381,     0.99349,     0.99317,     0.99256,     0.99203,     0.99148,     0.99041,      0.9895,      0.9884,     0.98768,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96218,     0.96218,      0.9564,     0.95164,     0.94648,      0.9411,     0.93656,     0.93222,      0.9285,     0.92333,     0.91899,     0.91465,     0.91031,     0.90597,     0.90287,     0.89977,     0.89729,     0.89295,     0.89068,     0.88903,     0.88675,     0.88386,     0.88097,\n",
              "            0.87869,     0.87683,     0.87394,     0.87208,      0.8696,     0.86774,     0.86588,     0.86423,     0.86237,     0.86072,     0.85906,       0.857,     0.85596,     0.85369,       0.851,     0.84956,      0.8479,     0.84584,     0.84501,     0.84336,     0.84191,     0.84088,      0.8384,\n",
              "            0.83778,      0.8355,     0.83344,     0.83199,     0.83075,     0.82972,     0.82868,      0.8262,     0.82538,     0.82414,     0.82269,     0.82062,     0.81897,     0.81732,     0.81566,     0.81496,      0.8138,     0.81132,     0.81008,     0.80802,     0.80698,     0.80451,     0.80244,\n",
              "             0.8012,     0.80017,     0.79851,     0.79727,     0.79645,     0.79562,     0.79417,     0.79293,      0.7919,     0.79045,     0.78942,      0.7888,     0.78818,     0.78715,     0.78653,     0.78632,      0.7857,     0.78549,     0.78384,     0.78288,     0.78115,     0.77971,     0.77847,\n",
              "            0.77785,     0.77681,     0.77557,     0.77495,     0.77309,     0.77165,     0.77041,     0.76999,     0.76958,     0.76896,     0.76751,     0.76648,     0.76525,     0.76421,     0.76338,     0.76255,     0.76214,     0.76069,     0.76069,     0.75966,     0.75863,      0.7578,     0.75718,\n",
              "            0.75677,     0.75553,     0.75532,      0.7547,     0.75449,     0.75367,     0.75284,      0.7514,     0.75119,     0.75057,     0.74954,      0.7483,     0.74685,     0.74644,     0.74602,      0.7452,     0.74458,     0.74313,      0.7423,     0.74148,     0.74086,     0.74024,      0.7398,\n",
              "            0.73879,     0.73776,     0.73693,     0.73631,     0.73548,     0.73445,     0.73321,     0.73073,      0.7301,     0.72804,     0.72784,     0.72722,     0.72639,     0.72556,     0.72474,     0.72391,     0.72366,     0.72267,     0.72224,       0.721,     0.72081,      0.7204,     0.71957,\n",
              "            0.71874,     0.71833,     0.71709,     0.71647,     0.71564,     0.71523,     0.71482,     0.71316,     0.71275,     0.71213,     0.71125,     0.71068,     0.71048,     0.70965,     0.70903,     0.70779,     0.70738,     0.70676,     0.70655,     0.70552,     0.70552,      0.7049,     0.70442,\n",
              "            0.70345,     0.70283,     0.70159,     0.70118,     0.70118,     0.70014,     0.69969,      0.6987,     0.69818,     0.69704,     0.69684,     0.69642,     0.69477,     0.69436,     0.69353,     0.69353,     0.69312,     0.69271,     0.69153,     0.69064,     0.69064,     0.68816,     0.68756,\n",
              "            0.68661,     0.68485,     0.68485,     0.68361,     0.68299,     0.68258,     0.68258,     0.68196,     0.68134,      0.6801,     0.67989,     0.67948,     0.67927,     0.67886,     0.67886,     0.67845,     0.67721,     0.67679,     0.67665,     0.67576,     0.67452,     0.67307,     0.67307,\n",
              "            0.67225,     0.67163,     0.67163,     0.67039,     0.66961,      0.6689,     0.66862,      0.6677,     0.66708,     0.66708,     0.66646,     0.66611,     0.66481,     0.66481,     0.66439,     0.66274,     0.66253,     0.66171,     0.66109,     0.66088,     0.66026,     0.65923,     0.65923,\n",
              "            0.65737,     0.65695,     0.65695,     0.65588,     0.65468,     0.65468,     0.65365,     0.65261,      0.6522,      0.6522,     0.65108,     0.65096,     0.64993,     0.64889,     0.64889,     0.64823,     0.64745,     0.64689,     0.64621,     0.64559,     0.64559,     0.64497,     0.64307,\n",
              "             0.6429,     0.64207,     0.64147,     0.64104,     0.64008,     0.64001,     0.63897,     0.63856,     0.63836,     0.63653,     0.63501,     0.63464,      0.6341,     0.63402,     0.63328,     0.63278,     0.63278,     0.63226,     0.63112,     0.63112,      0.6305,      0.6305,     0.62988,\n",
              "            0.62947,     0.62926,     0.62885,     0.62868,     0.62802,     0.62692,     0.62678,     0.62603,     0.62596,     0.62509,     0.62472,      0.6244,     0.62389,     0.62306,     0.62286,     0.62224,     0.62203,     0.62162,     0.62162,     0.62038,     0.62014,     0.62002,     0.61928,\n",
              "            0.61916,       0.618,     0.61707,     0.61707,     0.61686,     0.61686,     0.61624,     0.61624,     0.61562,     0.61435,     0.61423,     0.61335,     0.61335,     0.61273,     0.61273,       0.612,     0.61126,     0.61114,     0.61046,     0.61046,     0.60995,     0.60838,     0.60828,\n",
              "            0.60674,     0.60674,     0.60591,     0.60591,     0.60508,     0.60426,     0.60415,      0.6026,      0.6026,     0.60173,     0.60161,      0.6013,     0.60119,     0.59992,     0.59992,     0.59888,     0.59764,     0.59764,     0.59744,     0.59744,     0.59578,     0.59578,     0.59496,\n",
              "            0.59496,      0.5933,     0.59245,     0.59235,     0.59144,     0.59144,     0.59062,     0.59062,     0.58896,     0.58896,     0.58763,     0.58752,     0.58575,     0.58483,     0.58483,     0.58335,     0.58324,     0.58277,     0.58277,     0.58125,     0.58114,     0.58082,     0.57966,\n",
              "            0.57956,     0.57821,     0.57811,     0.57759,     0.57746,     0.57714,     0.57704,     0.57636,     0.57636,     0.57527,     0.57514,     0.57367,     0.57367,     0.57202,     0.57202,     0.57119,     0.57097,     0.57086,     0.56995,     0.56995,     0.56951,      0.5694,     0.56789,\n",
              "            0.56789,     0.56782,     0.56771,     0.56727,     0.56727,     0.56582,     0.56582,     0.56417,     0.56417,     0.56283,     0.56167,     0.56157,     0.55941,     0.55941,     0.55859,     0.55859,     0.55714,     0.55714,     0.55673,     0.55673,     0.55503,     0.55491,     0.55342,\n",
              "            0.55342,      0.5528,      0.5528,     0.55148,     0.55138,      0.5497,      0.5497,     0.54867,     0.54867,     0.54805,     0.54805,     0.54639,     0.54639,     0.54505,     0.54433,     0.54433,     0.54308,     0.54296,     0.54123,     0.54123,     0.54015,     0.54004,     0.53937,\n",
              "            0.53937,     0.53766,     0.53755,       0.536,     0.53589,     0.53496,     0.53486,      0.5331,     0.53299,     0.53185,     0.53175,     0.53048,     0.53048,     0.52945,     0.52945,     0.52832,     0.52822,     0.52697,     0.52697,     0.52604,     0.52552,     0.52552,     0.52386,\n",
              "            0.52376,     0.52179,     0.52168,     0.52034,     0.52023,     0.51726,     0.51726,     0.51599,     0.51588,     0.51374,     0.51374,     0.51288,     0.51277,     0.51163,     0.51153,     0.51064,     0.51064,     0.51018,     0.51007,     0.50934,     0.50924,     0.50707,     0.50696,\n",
              "            0.50568,     0.50568,     0.50458,     0.50447,     0.50362,     0.50362,     0.50196,     0.50196,     0.50063,     0.50053,     0.49907,     0.49907,     0.49835,     0.49824,     0.49649,     0.49493,     0.49483,      0.4937,      0.4937,     0.49244,     0.49234,     0.49161,     0.49151,\n",
              "            0.49037,     0.49026,     0.48853,     0.48853,     0.48767,     0.48756,     0.48646,     0.48646,     0.48539,     0.48528,     0.48455,     0.48445,      0.4831,       0.483,     0.48171,     0.48171,     0.48082,     0.48071,     0.48019,     0.48009,     0.47874,     0.47864,     0.47758,\n",
              "            0.47758,     0.47654,     0.47654,     0.47572,     0.47572,     0.47435,       0.472,       0.472,     0.47071,      0.4706,     0.46905,     0.46894,      0.4676,     0.46749,     0.46642,     0.46642,     0.46477,     0.46477,     0.46332,     0.46332,     0.46167,     0.46167,     0.46054,\n",
              "            0.46044,      0.4596,      0.4596,     0.45898,     0.45898,     0.45722,     0.45671,     0.45671,     0.45541,      0.4553,     0.45375,     0.45364,     0.45278,     0.45278,     0.45146,     0.45136,     0.45042,     0.45032,     0.44939,     0.44928,     0.44823,     0.44823,     0.44823,\n",
              "            0.44736,     0.44725,     0.44549,     0.44539,     0.44342,     0.44332,     0.44197,     0.44186,      0.4407,     0.44036,     0.44025,     0.43953,     0.43942,     0.43831,     0.43831,     0.43704,     0.43693,     0.43578,     0.43564,      0.4345,     0.43439,     0.43366,     0.43211,\n",
              "            0.43201,     0.43128,     0.43117,     0.43024,      0.4301,     0.42798,     0.42798,     0.42667,     0.42656,     0.42584,     0.42573,     0.42436,     0.42364,     0.42364,     0.42195,     0.42184,     0.41986,     0.41972,     0.41837,     0.41703,     0.41703,     0.41557,     0.41543,\n",
              "             0.4149,     0.41479,     0.41407,     0.41396,       0.413,     0.41184,     0.41173,     0.41083,     0.41083,     0.40959,     0.40959,     0.40826,     0.40815,     0.40739,     0.40649,     0.40649,     0.40582,     0.40571,     0.40546,       0.404,     0.40389,     0.40316,     0.40302,\n",
              "            0.40249,     0.40239,     0.40029,     0.39964,     0.39954,     0.39921,     0.39907,     0.39834,     0.39823,      0.3976,     0.39632,     0.39621,     0.39554,     0.39491,     0.39481,     0.39408,     0.39394,     0.39279,     0.39268,     0.39152,     0.39035,     0.39024,      0.3883,\n",
              "             0.3883,     0.38636,     0.38626,     0.38426,     0.38309,     0.38295,      0.3818,      0.3817,      0.3797,     0.37914,     0.37797,     0.37786,     0.37735,     0.37735,     0.37623,     0.37508,     0.37508,     0.37319,     0.37305,     0.37105,     0.37009,     0.36998,     0.36945,\n",
              "            0.36931,     0.36855,     0.36696,     0.36682,     0.36527,     0.36516,     0.36378,     0.36343,     0.36185,      0.3617,     0.36117,     0.36106,     0.35979,     0.35896,     0.35896,     0.35741,     0.35686,     0.35672,     0.35575,     0.35395,     0.35381,     0.35308,     0.35298,\n",
              "            0.35222,     0.35187,     0.35173,     0.35118,     0.34938,     0.34821,     0.34807,      0.3471,     0.34675,     0.34661,     0.34585,     0.34491,     0.34491,     0.34356,     0.34198,     0.34183,     0.33974,     0.33845,     0.33831,     0.33796,     0.33638,     0.33623,     0.33465,\n",
              "            0.33306,     0.33271,     0.33257,     0.33036,     0.32856,     0.32691,     0.32677,     0.32518,     0.32339,     0.32325,      0.3229,     0.32152,     0.32138,     0.31979,       0.319,     0.31778,     0.31764,     0.31626,     0.31529,     0.31515,     0.31453,     0.31397,     0.31342,\n",
              "            0.31267,     0.31267,      0.3113,     0.30865,     0.30686,     0.30672,     0.30585,     0.30471,     0.30333,     0.30319,     0.30134,     0.30057,     0.29898,     0.29884,      0.2976,     0.29683,     0.29563,     0.29462,     0.29406,     0.29344,      0.2933,     0.29188,      0.2913,\n",
              "            0.29011,     0.28805,     0.28791,     0.28669,     0.28508,     0.28327,     0.28204,      0.2819,     0.28129,     0.27948,     0.27828,     0.27745,       0.275,     0.27485,     0.27299,     0.27092,     0.27078,     0.26936,     0.26832,     0.26567,     0.26449,     0.26345,      0.2618,\n",
              "            0.26166,     0.26085,     0.25961,     0.25774,     0.25604,     0.25473,     0.25369,     0.25162,     0.25017,     0.24861,     0.24861,     0.24737,     0.24405,     0.24219,     0.24074,     0.23867,     0.23763,     0.23681,     0.23666,     0.23606,     0.23461,     0.23357,     0.23274,\n",
              "            0.23149,     0.23087,     0.22983,       0.229,     0.22858,     0.22796,     0.22649,     0.22443,     0.22257,     0.21966,     0.21915,     0.21811,     0.21707,     0.21624,     0.21458,     0.21375,      0.2125,     0.21115,     0.21032,     0.20928,     0.20763,     0.20569,     0.20545,\n",
              "            0.20482,     0.20337,     0.20004,     0.19912,     0.19861,     0.19798,     0.19632,     0.19568,     0.19414,     0.19269,     0.19051,     0.18965,     0.18895,      0.1877,     0.18491,     0.18382,     0.18294,     0.18055,     0.17966,     0.17713,     0.17545,     0.17392,     0.17235,\n",
              "            0.16916,     0.16823,     0.16739,     0.16501,     0.16304,     0.16157,     0.15848,      0.1568,     0.15413,     0.15306,     0.15257,     0.15015,     0.14755,     0.14693,     0.14522,     0.14452,     0.14203,     0.14034,     0.13788,     0.13672,       0.136,      0.1333,     0.13133,\n",
              "            0.12915,     0.12604,      0.1246,     0.12416,      0.1225,     0.12104,     0.11896,      0.1173,     0.11549,     0.11535,     0.11375,     0.11064,     0.10877,     0.10711,     0.10462,     0.10275,    0.099432,    0.098182,    0.096312,    0.093202,    0.091125,    0.087601,    0.085938,\n",
              "           0.084068,    0.082404,     0.08074,     0.07763,       0.077,     0.07389,     0.07202,    0.069116,    0.067039,    0.064549,    0.062059,    0.060808,    0.058318,    0.055415,    0.053751,    0.052708,    0.049184,    0.046487,     0.04317,    0.041729,    0.040877,    0.039006,    0.037136,\n",
              "           0.035679,    0.033189,    0.031525,    0.030069,    0.027578,    0.025708,    0.024045,    0.021348,    0.019477,    0.017607,    0.016564,    0.014786,    0.013856,    0.013019,    0.010529,   0.0094856,   0.0088553,   0.0083489,   0.0069747,   0.0061378,   0.0053008,   0.0048151,   0.0038336,\n",
              "          0.0032032,   0.0023663,   0.0019426,   0.0014828,  0.00068202,  0.00049943,  0.00033067,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.548265618560166)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,\n",
              "           0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,\n",
              "           0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,\n",
              "           0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052,     0.53052])\n",
              "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush', 80: 'box'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': np.float64(0.7480029003788697), 'metrics/recall(B)': np.float64(0.6026038437693738), 'metrics/mAP50(B)': np.float64(0.707968632758438), 'metrics/mAP50-95(B)': np.float64(0.5305208392048024), 'fitness': np.float64(0.548265618560166)}\n",
              "save_dir: PosixPath('runs/detect/train')\n",
              "speed: {'preprocess': 0.27003926550150936, 'inference': 4.786495800501598, 'loss': 0.0009815835019253427, 'postprocess': 2.464110163996338}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Download the trained model\n",
        "from google.colab import files\n",
        "files.download(\"runs/detect/train/weights/best.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Fi65DD-tnxUl",
        "outputId": "fe3fba2b-f140-45c5-a94a-215a609fb89a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42235954-02be-4cdb-b113-b3ff7913530c\", \"best.pt\", 4882114)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gm7DWJqQ-V6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}